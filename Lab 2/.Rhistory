tema = "aécio"
all_aecio = get_words_tema(noticias_folha, tema, 20)
filtra_palavras_por_morfologia = function(palavras_mais_similares, base_tema){
get_uma_noticia <- function(word){
base_tema %>% noticias_tema(word, "conteudo_processado") %>% slice(sample(1:n(), 1)) %>% select("conteudo")
}
noticias = palavras_mais_similares %>% rowwise() %>% mutate(noticia = get_uma_noticia(word))
morfo_obj = c("NOUN","PROPN","ADJ")
morfo = udpipe_annotate(ud_model, x = noticias$noticia) %>%
as.data.frame(morfo) %>%
filter(tolower(token) %in% noticias$word, upos %in% morfo_obj)
palavras_filtradas = morfo$token %>% tolower() %>% unique()
pmsf = palavras_mais_similares %>% filter(word %in% palavras_filtradas)
return(pmsf)
}
get_words_tema <- function(base, tema, n, tema_out = F){
campo = "conteudo_processado"
base_tema = base %>% noticias_tema(tema, campo)
if(tema_out!=F){
base_tema = base_tema %>% noticias_tema(tema_out, campo, get_from_pattern = F)
}
we_base = cria_word_embedding(tema, n_layers, NULL, base_tema, campo, path_saida)
we = we_base[[1]]
palavras_similares = closest_to(we, we[[tema]], n=n)
palavras_similares_filtradas = filtra_palavras_por_morfologia(palavras_similares, base_tema)
list(we, palavras_similares, palavras_similares_filtradas)
}
base_tema = noticias_folha %>% noticias_tema("aécio", "conteudo_processado")
palavras_mais_similares = all_aecio[[3]]
filtra_palavras_por_morfologia(palavras_mais_similares, base_tema)
base_tema = noticias_folha %>% noticias_tema("aécio", "conteudo_processado")
palavras_mais_similares = all_aecio[[3]]
get_uma_noticia <- function(word){
base_tema %>% noticias_tema(word, "conteudo_processado") %>% slice(sample(1:n(), 1)) %>% select("conteudo")
}
noticias = palavras_mais_similares %>% rowwise() %>% mutate(noticia = get_uma_noticia(word))
morfo_obj = c("NOUN","PROPN","ADJ")
morfo = udpipe_annotate(ud_model, x = noticias$noticia) %>%
as.data.frame(morfo) %>%
filter(tolower(token) %in% noticias$word, upos %in% morfo_obj)
morfo = udpipe_annotate(ud_model, x = noticias$noticia)
noticias$noticia
noticias$
morfo_obj = c("NOUN","PROPN","ADJ")
noticias$noticia
a=noticias$noticia
View(a)
noticias = palavras_mais_similares %>% rowwise() %>% mutate(noticia = get_uma_noticia(word))
View(noticias)
noticias = palavras_mais_similares %>% rowwise() %>% summarise(noticia = get_uma_noticia(word))
View(noticias)
source("../../utils/mongo_utils.R")
source("../../utils/utils.R")
source("../../utils/embeddings_utils.R")
source("../cria_word_embedding.R")
library("wordVectors")
library("readr")
library("udpipe")
n_layers = 300
data_inicio = "2014-01-01"
data_fim = "2014-12-31"
path_saida = "embeddings_teste/"
ud_model <- udpipe_load_model(file = "portuguese-br-ud-2.0-170801.udpipe")
### Importa base de dados
noticias <- get_todas_noticias_processadas() %>% filter(timestamp >= data_inicio & timestamp <= data_fim)
noticias_folha <- noticias %>% filter(subFonte == "FOLHASP")
#noticias_estadao <- noticias %>% filter(subFonte == "ESTADAO")
#noticias <- noticias_folha %>% bind_rows(noticias_estadao)
filtra_palavras_por_morfologia = function(palavras_mais_similares, base_tema){
get_uma_noticia <- function(word){
base_tema %>% noticias_tema(word, "conteudo_processado") %>% slice(sample(1:n(), 1)) %>% select("conteudo")
}
noticias = palavras_mais_similares %>% rowwise() %>% mutate(noticia = get_uma_noticia(word))
morfo_obj = c("NOUN","PROPN","ADJ")
morfo = udpipe_annotate(ud_model, x = noticias$noticia) %>%
as.data.frame(morfo) %>%
filter(tolower(token) %in% noticias$word, upos %in% morfo_obj)
palavras_filtradas = morfo$token %>% tolower() %>% unique()
pmsf = palavras_mais_similares %>% filter(word %in% palavras_filtradas)
return(pmsf)
}
get_words_tema <- function(base, tema, n, tema_out = F){
campo = "conteudo_processado"
base_tema = base %>% noticias_tema(tema, campo)
if(tema_out!=F){
base_tema = base_tema %>% noticias_tema(tema_out, campo, get_from_pattern = F)
}
we_base = cria_word_embedding(tema, n_layers, NULL, base_tema, campo, path_saida)
we = we_base[[1]]
palavras_similares = closest_to(we, we[[tema]], n=n)
palavras_similares_filtradas = filtra_palavras_por_morfologia(palavras_similares, base_tema)
list(we, palavras_similares, palavras_similares_filtradas)
}
tema = "aécio"
all_aecio = get_words_tema(noticias_folha, tema, 20)
get_words_tema <- function(base, tema, n, tema_out = F){
campo = "conteudo_processado"
base_tema = base %>% noticias_tema(tema, campo)
if(tema_out!=F){
base_tema = base_tema %>% noticias_tema(tema_out, campo, get_from_pattern = F)
}
we_base = cria_word_embedding(tema, n_layers, NULL, base_tema, campo, path_saida)
we = we_base[[1]]
palavras_similares = closest_to(we, we[[tema]], n=n)
list(we, palavras_similares)
}
tema = "aécio"
all_aecio = get_words_tema(noticias_folha, tema, 20)
all_aecio
base_tema = noticias_folha %>% noticias_tema("aécio", "conteudo_processado")
palavras_mais_similares = all_aecio[[3]]
palavras_mais_similares = all_aecio[[2]]
palavras_mais_similares
get_uma_noticia <- function(word){
base_tema %>% noticias_tema(word, "conteudo_processado") %>% slice(sample(1:n(), 1)) %>% select("conteudo")
}
noticias = palavras_mais_similares %>% rowwise() %>% summarise(noticia = get_uma_noticia(word))
View(noticias)
noticias = palavras_mais_similares %>% summarise(noticia = get_uma_noticia(word))
noticias = palavras_mais_similares %>% mutate(noticia = get_uma_noticia(word))
noticias = palavras_mais_similares %>% rowwise() %>% mutate(noticia = get_uma_noticia(word))
View(noticias)
noticias
get_uma_noticia("aécio")
a=get_uma_noticia("aécio")
View(a)
a=get_uma_noticia("psdb")
View(a)
a=get_uma_noticia("PSDB")
View(a)
a=get_uma_noticia("psdb")
View(a)
a=get_uma_noticia("psdb")
View(a)
a=get_uma_noticia("cumprirá")
View(a)
a=get_uma_noticia("cheiro")
View(a)
get_uma_noticia <- function(word){
noticia = base_tema %>% noticias_tema(word, "conteudo_processado") %>% slice(sample(1:n(), 1))
noticia$conteudo
}
get_uma_noticia("aécio")
noticias = palavras_mais_similares %>% rowwise() %>% mutate(noticia = get_uma_noticia(word))
View(noticias)
morfo_obj = c("NOUN","PROPN","ADJ")
morfo = udpipe_annotate(ud_model, x = noticias$noticia) %>%
as.data.frame(morfo) %>%
filter(tolower(token) %in% noticias$word, upos %in% morfo_obj)
palavras_filtradas = morfo$token %>% tolower() %>% unique()
pmsf = palavras_mais_similares %>% filter(word %in% palavras_filtradas)
pmsf
View(pmsf)
base_tema = noticias_folha %>% noticias_tema("aécio", "conteudo_processado")
palavras_mais_similares = all_aecio[[2]]
get_uma_noticia <- function(word){
noticia = base_tema %>% noticias_tema(word, "conteudo_processado") %>% slice(sample(1:n(), 1))
noticia$conteudo
}
noticias = palavras_mais_similares %>% rowwise() %>% mutate(noticia = get_uma_noticia(word))
morfo_obj = c("NOUN","PROPN","ADJ")
morfo = udpipe_annotate(ud_model, x = noticias$noticia) %>%
as.data.frame(morfo) %>%
filter(tolower(token) %in% noticias$word, upos %in% morfo_obj)
palavras_filtradas = morfo$token %>% tolower() %>% unique()
pmsf = palavras_mais_similares %>% filter(word %in% palavras_filtradas)
pmsf
View(pmsf)
filtra_palavras_por_morfologia(palavras_mais_similares, base_tema)
filtra_palavras_por_morfologia = function(palavras_mais_similares, base_tema){
get_uma_noticia <- function(word){
noticia = base_tema %>% noticias_tema(word, "conteudo_processado") %>% slice(sample(1:n(), 1))
noticia$conteudo
}
noticias = palavras_mais_similares %>% rowwise() %>% mutate(noticia = get_uma_noticia(word))
morfo_obj = c("NOUN","PROPN","ADJ")
morfo = udpipe_annotate(ud_model, x = noticias$noticia) %>%
as.data.frame(morfo) %>%
filter(tolower(token) %in% noticias$word, upos %in% morfo_obj)
palavras_filtradas = morfo$token %>% tolower() %>% unique()
pmsf = palavras_mais_similares %>% filter(word %in% palavras_filtradas)
return(pmsf)
}
get_words_tema <- function(base, tema, n, tema_out = F){
campo = "conteudo_processado"
base_tema = base %>% noticias_tema(tema, campo)
if(tema_out!=F){
base_tema = base_tema %>% noticias_tema(tema_out, campo, get_from_pattern = F)
}
we_base = cria_word_embedding(tema, n_layers, NULL, base_tema, campo, path_saida)
we = we_base[[1]]
palavras_similares = closest_to(we, we[[tema]], n=n)
list(we, palavras_similares)
}
base_tema = noticias_folha %>% noticias_tema("aécio", "conteudo_processado")
palavras_mais_similares = all_aecio[[2]]
filtra_palavras_por_morfologia(palavras_mais_similares, base_tema)
palavras_filtradas = filtra_palavras_por_morfologia(palavras_mais_similares, base_tema)
palavras_filtradas
get_words_tema <- function(base, tema, n, tema_out = F){
campo = "conteudo_processado"
base_tema = base %>% noticias_tema(tema, campo)
if(tema_out!=F){
base_tema = base_tema %>% noticias_tema(tema_out, campo, get_from_pattern = F)
}
we_base = cria_word_embedding(tema, n_layers, NULL, base_tema, campo, path_saida)
we = we_base[[1]]
palavras_similares = closest_to(we, we[[tema]], n=n) %>% rename("word", "similarity")
list(we, palavras_similares)
}
all_aecio[[2]] %>% rename("word", "similarity")
colnames(all_aecio[[2]]) <- ("word", "similarity")
colnames(all_aecio[[2]]) <- c("word", "similarity")
all_aecio[[2]]
get_words_tema <- function(base, tema, n, tema_out = F){
campo = "conteudo_processado"
base_tema = base %>% noticias_tema(tema, campo)
if(tema_out!=F){
base_tema = base_tema %>% noticias_tema(tema_out, campo, get_from_pattern = F)
}
we_base = cria_word_embedding(tema, n_layers, NULL, base_tema, campo, path_saida)
we = we_base[[1]]
palavras_similares = closest_to(we, we[[tema]], n=n)
colnames(palavras_similares) <- c("word", "similarity")
list(we, palavras_similares)
}
palavras_mais_similares = all_aecio[[2]]
palavras_filtradas = filtra_palavras_por_morfologia(palavras_mais_similares, base_tema)
palavras_filtradas
palavras_filtradas$similarity
palavras_filtradas$similarity[-1]
sim = palavras_filtradas$similarity
sim[-length(sim)]
sim[-1]
sim[-length(sim)]
sim[-length(sim)] - sim[-1]
sort(sim_dif, TRUE)
sim_dif = sim[-length(sim)] - sim[-1]
sort(sim_dif, TRUE)
sort(sim_dif, TRUE)[2] #maior diferenca eh esperado que seja da primeira para a segunda palavra. Queremos, entao, a segunda maior diferenca.
?which
which(sim_dif == max_dif)
max_dif = sort(sim_dif, TRUE)[2] #maior diferenca eh esperado que seja da primeira para a segunda palavra. Queremos, entao, a segunda maior diferenca.
which(sim_dif == max_dif)
pos = which(sim_dif == max_dif)
palavras_filtradas %>% slice(1:pos)
palavras_fil_morfo = filtra_palavras_por_morfologia(palavras_mais_similares, base_tema)
filtra_palavras_por_distancia <- function(similaridade_palavras){
sim = similaridade_palavras$similarity
sim_dif = sim[-length(sim)] - sim[-1]
max_dif = sort(sim_dif, TRUE)[2] #maior diferenca eh esperado que seja da primeira para a segunda palavra. Queremos, entao, a segunda maior diferenca.
pos = which(sim_dif == max_dif)
palavras_filtradas = similaridade_palavras %>% slice(1:pos)
return(palavras_filtradas)
}
filtra_palavras_por_distancia <- function(similaridade_palavras){
sim = similaridade_palavras$similarity
sim_dif = sim[-length(sim)] - sim[-1]
max_dif = sort(sim_dif, TRUE)[2] #maior diferenca eh esperado que seja da primeira para a segunda palavra. Queremos, entao, a segunda maior diferenca.
pos = which(sim_dif == max_dif)
palavras_filtradas = similaridade_palavras %>% slice(1:pos)
return(palavras_filtradas)
}
filtra_palavras_por_distancia(palavras_fil_morfo)
source("../../utils/mongo_utils.R")
source("../../utils/utils.R")
source("../../utils/embeddings_utils.R")
source("../cria_word_embedding.R")
library("wordVectors")
library("readr")
library("udpipe")
n_layers = 300
data_inicio = "2014-01-01"
data_fim = "2014-12-31"
path_saida = "embeddings_teste/"
ud_model <- udpipe_load_model(file = "portuguese-br-ud-2.0-170801.udpipe")
### Importa base de dados
noticias <- get_todas_noticias_processadas() %>% filter(timestamp >= data_inicio & timestamp <= data_fim)
noticias_folha <- noticias %>% filter(subFonte == "FOLHASP")
#noticias_estadao <- noticias %>% filter(subFonte == "ESTADAO")
#noticias <- noticias_folha %>% bind_rows(noticias_estadao)
filtra_palavras_por_morfologia = function(palavras_mais_similares, base_tema){
get_uma_noticia <- function(word){
noticia = base_tema %>% noticias_tema(word, "conteudo_processado") %>% slice(sample(1:n(), 1))
noticia$conteudo
}
noticias = palavras_mais_similares %>% rowwise() %>% mutate(noticia = get_uma_noticia(word))
morfo_obj = c("NOUN","PROPN","ADJ")
morfo = udpipe_annotate(ud_model, x = noticias$noticia) %>%
as.data.frame(morfo) %>%
filter(tolower(token) %in% noticias$word, upos %in% morfo_obj)
palavras_filtradas = morfo$token %>% tolower() %>% unique()
pmsf = palavras_mais_similares %>% filter(word %in% palavras_filtradas)
return(pmsf)
}
get_words_tema <- function(base, tema, n_prox, tema_out = F){
if(tema_out!=F){
base_tema = base_tema %>% noticias_tema(tema_out, campo, get_from_pattern = F)
}
we_base = cria_word_embedding(tema, n_layers, NULL, base_tema, campo, path_saida)
we = we_base[[1]]
palavras_similares = closest_to(we, we[[tema]], n=n_prox)
colnames(palavras_similares) <- c("word", "similarity")
list(we, palavras_similares)
}
filtra_palavras_por_distancia <- function(similaridade_palavras){
sim = similaridade_palavras$similarity
sim_dif = sim[-length(sim)] - sim[-1]
max_dif = sort(sim_dif, TRUE)[2] #maior diferenca eh esperado que seja da primeira para a segunda palavra. Queremos, entao, a segunda maior diferenca.
pos = which(sim_dif == max_dif)
palavras_filtradas = similaridade_palavras %>% slice(1:pos)
return(palavras_filtradas)
}
campo = "conteudo_processado"
tema = "aécio"
n_palavras_prox = 20
base_tema = base %>% noticias_tema(tema, campo)
base_tema = noticias_folha %>% noticias_tema(tema, campo)
campo = "conteudo_processado"
tema = "aécio"
n_palavras_prox = 20
base_tema = noticias_folha %>% noticias_tema(tema, campo)
palavras_similares = get_words_tema(base_tema, tema, n_palavras_prox)
palavras_similares = palavras_similares[[2]]
palavras_fil_morfo = filtra_palavras_por_morfologia(palavras_similares, base_tema)
filtra_palavras_por_distancia(palavras_fil_morfo)
source("../../utils/mongo_utils.R")
source("../../utils/utils.R")
source("../../utils/embeddings_utils.R")
source("../cria_word_embedding.R")
library("wordVectors")
library("readr")
library("udpipe")
n_layers = 300
data_inicio = "2014-01-01"
data_fim = "2014-12-31"
path_saida = "embeddings_teste/"
ud_model <- udpipe_load_model(file = "portuguese-br-ud-2.0-170801.udpipe")
### Importa base de dados
noticias <- get_todas_noticias_processadas() %>% filter(timestamp >= data_inicio & timestamp <= data_fim)
noticias_folha <- noticias %>% filter(subFonte == "FOLHASP")
#noticias_estadao <- noticias %>% filter(subFonte == "ESTADAO")
#noticias <- noticias_folha %>% bind_rows(noticias_estadao)
filtra_palavras_por_morfologia = function(palavras_mais_similares, base_tema){
get_uma_noticia <- function(word){
noticia = base_tema %>% noticias_tema(word, "conteudo_processado") %>% slice(sample(1:n(), 1))
noticia$conteudo
}
noticias = palavras_mais_similares %>% rowwise() %>% mutate(noticia = get_uma_noticia(word))
morfo_obj = c("NOUN","PROPN","ADJ")
morfo = udpipe_annotate(ud_model, x = noticias$noticia) %>%
as.data.frame(morfo) %>%
filter(tolower(token) %in% noticias$word, upos %in% morfo_obj)
palavras_filtradas = morfo$token %>% tolower() %>% unique()
pmsf = palavras_mais_similares %>% filter(word %in% palavras_filtradas)
return(pmsf)
}
get_words_tema <- function(base, tema, n_prox, tema_out = F){
if(tema_out!=F){
base_tema = base_tema %>% noticias_tema(tema_out, campo, get_from_pattern = F)
}
we_base = cria_word_embedding(tema, n_layers, NULL, base_tema, campo, path_saida)
we = we_base[[1]]
palavras_similares = closest_to(we, we[[tema]], n=n_prox)
colnames(palavras_similares) <- c("word", "similarity")
list(we, palavras_similares)
}
filtra_palavras_por_distancia <- function(similaridade_palavras){
sim = similaridade_palavras$similarity
sim_dif = sim[-length(sim)] - sim[-1]
max_dif = sort(sim_dif, TRUE)[2] #maior diferenca eh esperado que seja da primeira para a segunda palavra. Queremos, entao, a segunda maior diferenca.
pos = which(sim_dif == max_dif)
palavras_filtradas = similaridade_palavras %>% slice(1:pos)
return(palavras_filtradas)
}
cria_conjunto_de_entidade <- function(tema, base, campo, n_palavras_prox){
base_tema = base %>% noticias_tema(tema, campo)
palavras_similares = get_words_tema(base_tema, tema, n_palavras_prox)
palavras_similares = palavras_similares[[2]]
palavras_fil_morfo = filtra_palavras_por_morfologia(palavras_similares, base_tema)
palavras_escolhidas = filtra_palavras_por_distancia(palavras_fil_morfo)
return(palavras_escolhidas)
}
campo = "conteudo_processado"
tema = "aécio"
n_palavras_prox = 20
cria_conjunto_de_entidade(tema, noticias_folha, campo, n_palavras_prox)
get_words_tema <- function(base_tema, tema, n_prox, tema_out = F){
if(tema_out!=F){
base_tema = base_tema %>% noticias_tema(tema_out, campo, get_from_pattern = F)
}
we_base = cria_word_embedding(tema, n_layers, NULL, base_tema, campo, path_saida)
we = we_base[[1]]
palavras_similares = closest_to(we, we[[tema]], n=n_prox)
colnames(palavras_similares) <- c("word", "similarity")
list(we, palavras_similares)
}
campo = "conteudo_processado"
tema = "aécio"
n_palavras_prox = 20
cria_conjunto_de_entidade(tema, noticias_folha, campo, n_palavras_prox)
cria_conjunto_de_entidade <- function(tema, base, campo, n_palavras_prox){
base_tema = base %>% noticias_tema(tema, campo)
palavras_similares = get_words_tema(base_tema, tema, n_palavras_prox)
palavras_similares = palavras_similares[[2]]
print(palavras_similares)
palavras_fil_morfo = filtra_palavras_por_morfologia(palavras_similares, base_tema)
print(palavras_fil_morfo)
palavras_escolhidas = filtra_palavras_por_distancia(palavras_fil_morfo)
return(palavras_escolhidas)
}
cria_conjunto_de_entidade(tema, noticias_folha, campo, n_palavras_prox)
tema = "dilma"
cria_conjunto_de_entidade(tema, noticias_folha, campo, n_palavras_prox)
library("stats")
library("ggbiplot")
library("dplyr")
library("Rtsne")
library("ggplot2")
source("../utils/mongo_utils.R")
source("../utils/utils.R")
source("../word_embeddings/cria_word_embedding.R")
source("../word_embeddings/eleicoes_2014/cria_conjuntos.R")
source("../2017-Caliskan-WEAT/weat.R")
source("busca_top_rated_comentarios.R")
load("~/workspace/PhD/src/vies_jornais/aplicacao_word2vec/EMNLP/bias_compare_methodology.RData")
#atributos globais
campo = "conteudo_processado"
n_layers = 300
ud_model <- udpipe_load_model(file = "portuguese-br-ud-2.0-170801.udpipe")
we_wikipedia_pt = read.binary.vectors("../word_embeddings/wikipedia_pt/embeddings/pt_2.bin")
noticias <- get_todas_noticias_processadas()
View(noticias_eleicao_estadao)
noticias_comentarios_eleicao_folha = bind_rows(noticias_eleicao_folha, comentarios_folha_eleicao)
noticias_comentarios_eleicao_folha_thumbs_up = bind_rows(noticias_eleicao_folha, comentarios_folha_top)
noticias_comentarios_eleicao_folha_thumbs_down = bind_rows(noticias_eleicao_folha, comentarios_folha_bottom)
noticias_comentarios_eleicao_folha = bind_rows(noticias_eleicao_folha, comentarios_folha_eleicao)
noticias_comentarios_eleicao_folha$subFonte = "COMENTARIOS-FOLHA"
dilma_comentarios = cria_conjunto_de_entidade("dilma", noticias_comentarios_eleicao_folha, campo, min_entidades)
aecio_comentarios = cria_conjunto_de_entidade("aécio", noticias_comentarios_eleicao_folha, campo, min_entidades)
marina_comentarios = cria_conjunto_de_entidade("marina", noticias_comentarios_eleicao_folha, campo, min_entidades)
conjuntos_noticias_comentarios = conjuntos_mesmo_tamanho(list(dilma_comentarios$word, aecio_comentarios$word, marina_comentarios$word))
dilma_comentarios = conjuntos_noticias_comentarios[[1]]
aecio_comentarios = conjuntos_noticias_comentarios[[2]]
marina_comentarios = conjuntos_noticias_comentarios[[3]]
pt_comentarios = cria_conjunto_de_entidade("pt", noticias_comentarios_eleicao_folha, campo, min_entidades)
psdb_comentarios = cria_conjunto_de_entidade("psdb", noticias_comentarios_eleicao_folha, campo, min_entidades)
psb_comentarios = cria_conjunto_de_entidade("psb", noticias_comentarios_eleicao_folha, campo, min_entidades)
conjuntos_noticias_comentarios = conjuntos_mesmo_tamanho(list(pt_comentarios$word, psdb_comentarios$word, psb_comentarios$word))
pt_comentarios = conjuntos_noticias_comentarios[[1]]
psdb_comentarios = conjuntos_noticias_comentarios[[2]]
psb_comentarios = conjuntos_noticias_comentarios[[3]]
noticias_comentarios_eleicao_folha_thumbs_up = bind_rows(noticias_eleicao_folha, comentarios_folha_top)
noticias_comentarios_eleicao_folha_thumbs_up$subFonte = "COMENTARIOS-TU"
dilma_thumbs_up = cria_conjunto_de_entidade("dilma", noticias_comentarios_eleicao_folha_thumbs_up, campo, min_entidades)
aecio_thumbs_up = cria_conjunto_de_entidade("aécio", noticias_comentarios_eleicao_folha_thumbs_up, campo, min_entidades)
marina_thumbs_up = cria_conjunto_de_entidade("marina", noticias_comentarios_eleicao_folha_thumbs_up, campo, min_entidades)
conjuntos_noticias_thumbs_up = conjuntos_mesmo_tamanho(list(dilma_thumbs_up$word, aecio_thumbs_up$word, marina_thumbs_up$word))
dilma_thumbs_up = conjuntos_noticias_thumbs_up[[1]]
aecio_thumbs_up = conjuntos_noticias_thumbs_up[[2]]
marina_thumbs_up = conjuntos_noticias_thumbs_up[[3]]
pt_thumbs_up = cria_conjunto_de_entidade("pt", noticias_comentarios_eleicao_folha_thumbs_up, campo, min_entidades)
psdb_thumbs_up = cria_conjunto_de_entidade("psdb", noticias_comentarios_eleicao_folha_thumbs_up, campo, min_entidades)
psb_thumbs_up = cria_conjunto_de_entidade("psb", noticias_comentarios_eleicao_folha_thumbs_up, campo, min_entidades)
conjuntos_noticias_thumbs_up = conjuntos_mesmo_tamanho(list(pt_thumbs_up$word, psdb_thumbs_up$word, psb_thumbs_up$word))
pt_thumbs_up = conjuntos_noticias_thumbs_up[[1]]
psdb_thumbs_up = conjuntos_noticias_thumbs_up[[2]]
psb_thumbs_up = conjuntos_noticias_thumbs_up[[3]]
noticias_comentarios_eleicao_folha_thumbs_down = bind_rows(noticias_eleicao_folha, comentarios_folha_bottom)
noticias_comentarios_eleicao_folha_thumbs_down$subFonte = "COMENTARIOS-TD"
dilma_thumbs_down = cria_conjunto_de_entidade("dilma", noticias_comentarios_eleicao_folha_thumbs_down, campo, min_entidades)
aecio_thumbs_down = cria_conjunto_de_entidade("aécio", noticias_comentarios_eleicao_folha_thumbs_down, campo, min_entidades)
marina_thumbs_down = cria_conjunto_de_entidade("marina", noticias_comentarios_eleicao_folha_thumbs_down, campo, min_entidades)
conjuntos_noticias_thumbs_down = conjuntos_mesmo_tamanho(list(dilma_thumbs_down$word, aecio_thumbs_down$word, marina_thumbs_down$word))
dilma_thumbs_down = conjuntos_noticias_thumbs_down[[1]]
aecio_thumbs_down = conjuntos_noticias_thumbs_down[[2]]
marina_thumbs_down = conjuntos_noticias_thumbs_down[[3]]
pt_thumbs_down = cria_conjunto_de_entidade("pt", noticias_comentarios_eleicao_folha_thumbs_down, campo, min_entidades)
psdb_thumbs_down = cria_conjunto_de_entidade("psdb", noticias_comentarios_eleicao_folha_thumbs_down, campo, min_entidades)
psb_thumbs_down = cria_conjunto_de_entidade("psb", noticias_comentarios_eleicao_folha_thumbs_down, campo, min_entidades)
conjuntos_noticias_thumbs_down = conjuntos_mesmo_tamanho(list(pt_thumbs_down$word, psdb_thumbs_down$word, psb_thumbs_down$word))
pt_thumbs_down = conjuntos_noticias_thumbs_down[[1]]
psdb_thumbs_down = conjuntos_noticias_thumbs_down[[2]]
psb_thumbs_down = conjuntos_noticias_thumbs_down[[3]]
save.image("~/workspace/PhD/src/vies_jornais/aplicacao_word2vec/EMNLP/bias_compare_methodology.RData")
setwd("~/workspace/Recuperação da Informação/Lab 2")
library("dplyr")
library("readr")
source("../Lab 1/Noticias/mongo_utils.R")
noticias <- get_collection("estadaoNoticiasProcessadas")
data_inicio = "2014-01-01"
data_fim = "2014-12-31"
noticias_eleicao = noticias %>% filter(timestamp >= data_inicio & timestamp <= data_fim) %>% select(timestamp, titulo, subTitulo, conteudo, url)
noticias_eleicao$idNoticia = 1:nrow(noticias_eleicao)
View(noticias_eleicao)
library("dplyr")
install.packages("dplyr")
library("dplyr")
library("readr")
rates <- read_csv("../data/soc-sign-bitcoinotc.csv")
rates <- read_csv("../data/soc-sign-bitcoinotc.csv")
rates <- read_csv("../data/soc-sign-bitcoinotc.csv")
greater_than_8 <- rates %>% filter(RATING >= 8)
write_csv("bitcoin_ratings.csv", greater_than_8)
write_csv(greater_than_8, "../data/bitcoin_ratings.csv")
View(greater_than_8)
library("dplyr")
library("readr")
rates <- read_csv("../data/soc-sign-bitcoinotc.csv")
greater_than_8 <- rates %>% filter(RATING >= 8) %>% select(-TIME)
write_csv(greater_than_8, "../data/bitcoin_ratings.csv")
View(greater_than_8)
